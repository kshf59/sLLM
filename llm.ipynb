{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3065fbc5-ae6f-419e-8e47-229b70988bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from huggingface_hub import login\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "import bitsandbytes as bnb\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training)\n",
    "\n",
    "from typing import Union\n",
    "from dotenv import load_dotenv\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "044a6d7b-ca64-4aa6-8891-f53564760b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('.env')\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "wandb_host = os.getenv(\"WANDB_HOST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645438b9-3c2f-4374-be93-fa2cfd857ea5",
   "metadata": {},
   "source": [
    "#### Wandb 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4243261c-5e4d-4cbb-9ba8-ccbb3b5c8359",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_wandb = False\n",
    "if use_wandb:\n",
    "    wandb.login(host = wandb_host)\n",
    "    wandb_run_name = 'Single_GPU_Optim'\n",
    "    wandb.init(project=\"llm_ksh\", name = wandb_run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbc4b96-eda8-4c89-a6f5-2df3763bda1e",
   "metadata": {},
   "source": [
    "!pip install -q -U bitsandbytes\n",
    "!pip install datasets -U\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install wandb\n",
    "!pip install pandas\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be3d2d63-4c17-4e62-a519-c1532d8c8196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/user1/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "my_hf_key = api_key\n",
    "login(my_hf_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f31e14c-ecdb-4acd-a71d-3379d2385c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "data_path = 'DopeorNope/Ko-Optimize_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd957cdd-5a41-4897-99d8-3b827ccc09ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d319b83b-b0eb-4f35-978a-f0896cc76f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d71d43a2-af66-4721-b081-9d773df13716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7794c99f-bd8b-439d-8588-d87bc4599e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct = []\n",
    "for qwer in range(len(df)):\n",
    "    if len(df['input'][qwer]) != 0:\n",
    "        distinct.append(df['input'][qwer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b21401f-904f-4d00-8cb7-f66305a198b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(set(distinct), columns = ['input'])\n",
    "tmp['length'] = tmp['input'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b590a64f-40bc-422b-99f9-d83e57f95407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>역할을 맡게 됩니다: 엘리너 루스벨트\\n1933년부터 1945년까지 남편 프랭클린 ...</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>동료 학생의 글을 검토할 때는 피드백을 명확하고 구체적으로 작성하세요. 다음과 같은...</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>당신은 인공지능 비서입니다. 사용자에게 과제가 주어집니다. 당신의 목표는 가능한 한...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>귀하는 항상 설명을 제공하는 도움이 되는 조수입니다. 5살짜리 아이에게 대답한다고 ...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>동료 검토 중에는 동료 학생의 글을 읽고 응답합니다. 텍스트를 검토하는 데 사용할 ...</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>귀하는 사람들이 정보를 찾도록 도와주는 AI 어시스턴트입니다. 사용자가 질문을 합니...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>잭과의 대화.\\n잭 설명: 카리스마 넘치는 세일즈맨인 잭이라는 캐릭터를 생각해 보세...</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>정의를 사용하여 답을 생각해낸 방법을 설명하세요.</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>솔루션으로 A, B, C 또는 D를 선택합니다.</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>스티븐 호킹과의 대화.\\n스티븐 호킹 설명: 이론 물리학 및 우주론 분야의 스티븐 ...</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>과제를 설명하고 답을 설명해야 합니다. 객관식 문제에 답할 때는 먼저 정답을 출력합...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>귀하는 교사입니다. 과제가 주어지면 과제에서 요구하는 내용, 과제에서 제공하는 지침...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>정확하고 간결한 답변을 제공하는 세계적인 수준의 퀴즈 AI입니다.</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>귀하는 AI 어시스턴트입니다. 과제를 설명하고 답을 설명해야 합니다. 객관식 문제에...</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>역할을 맡게 됩니다: 브루스 슈나이더\\n암호화 및 컴퓨터 과학 분야 출신인 브루스 ...</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>문장은 완전한 생각을 표현하는 단어의 집합입니다.\\n제가 속한 밴드는 2주 후에 콘...</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>역할을 맡게 됩니다: 비비안 솔라리스 박사\\n비비안 솔라리스 박사는 환경 과학 및 ...</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>노암 촘스키 박사(일명 어시스턴트)와 사용자 간의 대화.\\n노암 촘스키 박사:\\n노...</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>귀하는 AI 어시스턴트입니다. 과제가 주어집니다. 상세하고 긴 답변을 생성해야 합니다.</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>당신은 인공지능 비서입니다. 사용자가 답을 이해하기 위해 외부에서 검색할 필요가 없...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input  length\n",
       "0   역할을 맡게 됩니다: 엘리너 루스벨트\\n1933년부터 1945년까지 남편 프랭클린 ...     707\n",
       "1   동료 학생의 글을 검토할 때는 피드백을 명확하고 구체적으로 작성하세요. 다음과 같은...     418\n",
       "2   당신은 인공지능 비서입니다. 사용자에게 과제가 주어집니다. 당신의 목표는 가능한 한...     100\n",
       "3   귀하는 항상 설명을 제공하는 도움이 되는 조수입니다. 5살짜리 아이에게 대답한다고 ...      52\n",
       "4   동료 검토 중에는 동료 학생의 글을 읽고 응답합니다. 텍스트를 검토하는 데 사용할 ...     553\n",
       "5   귀하는 사람들이 정보를 찾도록 도와주는 AI 어시스턴트입니다. 사용자가 질문을 합니...     108\n",
       "6   잭과의 대화.\\n잭 설명: 카리스마 넘치는 세일즈맨인 잭이라는 캐릭터를 생각해 보세...     122\n",
       "7                         정의를 사용하여 답을 생각해낸 방법을 설명하세요.      27\n",
       "8                          솔루션으로 A, B, C 또는 D를 선택합니다.      26\n",
       "9   스티븐 호킹과의 대화.\\n스티븐 호킹 설명: 이론 물리학 및 우주론 분야의 스티븐 ...     338\n",
       "10  과제를 설명하고 답을 설명해야 합니다. 객관식 문제에 답할 때는 먼저 정답을 출력합...     100\n",
       "11  귀하는 교사입니다. 과제가 주어지면 과제에서 요구하는 내용, 과제에서 제공하는 지침...      86\n",
       "12               정확하고 간결한 답변을 제공하는 세계적인 수준의 퀴즈 AI입니다.      36\n",
       "13  귀하는 AI 어시스턴트입니다. 과제를 설명하고 답을 설명해야 합니다. 객관식 문제에...     126\n",
       "14  역할을 맡게 됩니다: 브루스 슈나이더\\n암호화 및 컴퓨터 과학 분야 출신인 브루스 ...     413\n",
       "15  문장은 완전한 생각을 표현하는 단어의 집합입니다.\\n제가 속한 밴드는 2주 후에 콘...     313\n",
       "16  역할을 맡게 됩니다: 비비안 솔라리스 박사\\n비비안 솔라리스 박사는 환경 과학 및 ...     629\n",
       "17  노암 촘스키 박사(일명 어시스턴트)와 사용자 간의 대화.\\n노암 촘스키 박사:\\n노...     301\n",
       "18   귀하는 AI 어시스턴트입니다. 과제가 주어집니다. 상세하고 긴 답변을 생성해야 합니다.      48\n",
       "19  당신은 인공지능 비서입니다. 사용자가 답을 이해하기 위해 외부에서 검색할 필요가 없...      63"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d15fab9f-a544-420e-a5ab-2381a429b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3dbcbd36-51a4-4ee3-a61c-d3a33b8d5ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 세팅 : QLoRA시 pad 토큰을 eos로 설정하기\n",
    "bos = tokenizer.bos_token_id\n",
    "eos = tokenizer.eos_token_id\n",
    "\n",
    "tokenizer.add_special_tokens({\"pad_token\" : \"<|reserved_special_token_0>\"})\n",
    "\n",
    "tokenizer.pad_token_id = eos\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06986c76-d8e0-4eff-9793-08392577bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off_len = 4098\n",
    "val_size = 0.005\n",
    "train_on_inputs = False\n",
    "add_eos_token = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "134a7a0c-68b0-4003-91e2-2c9bce824725",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = {\n",
    "    \"prompt_input\": \"아래는 문제를 설명하는 지시사항과, 구체적인 답변을 방식을 요구하는 입력이 함께 있는 문장입니다. 이 요청에 대해 적절하게 답변해주세요.\\n###입력:{input}\\n###지시사항:{instruction}\\n###답변:\",\n",
    "    \"prompt_no_input\": \"아래는 문제를 설명하는 지시사항입니다. 이 요청에 대해 적절하게 답변해주세요.\\n###지시사항:{instruction}\\n###답변\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bee468c1-e626-4c76-8710-d7f2896360b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(\n",
    "    instruction: str,\n",
    "    input: Union[None, str] = None,\n",
    "    label: Union[None, str] = None,\n",
    "    verbose: bool = False\n",
    ") -> str:\n",
    "    if input:\n",
    "        res = template[\"prompt_input\"].format(instruction=instruction, input=input)\n",
    "    else:\n",
    "        res = template[\"prompt_no_input\"].format(instruction=instruction)\n",
    "    if label:\n",
    "        res = f\"{res}{label}\"\n",
    "    if verbose:\n",
    "        print(res)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1deac4d5-0a6b-4d32-a4f5-a28c40b7f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(prompt, add_eos_token=True):\n",
    "    result = tokenizer(prompt, truncation=True, max_length=cut_off_len, padding=False, return_tensors=None,)\n",
    "    if (result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "        and len(result[\"input_ids\"]) < cut_off_len\n",
    "        and add_eos_token\n",
    "    ):\n",
    "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "        result[\"attention_mask\"].append(1)\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a70c7c06-4af2-4b2c-8c13-fd3ff6a42697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(\n",
    "        data_point[\"instruction\"],\n",
    "        data_point[\"input\"],\n",
    "        data_point[\"output\"]\n",
    "    )\n",
    "    tokenized_full_prompt = tokenize(full_prompt)\n",
    "    if not train_on_inputs:\n",
    "        user_prompt = generate_prompt(data_point[\"instruction\"], data_point[\"input\"])\n",
    "        tokenized_user_prompt = tokenize(user_prompt, add_eos_token=add_eos_token)\n",
    "        user_prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n",
    "\n",
    "        if add_eos_token:\n",
    "            user_prompt_len -= 1\n",
    "\n",
    "        tokenized_full_prompt[\"labels\"] = [-100] * user_prompt_len + tokenized_full_prompt[\"labels\"][user_prompt_len:]\n",
    "    return tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "417d2af8-2d97-4cf7-94a5-0f032f35b039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8345aa04c03d4c71a1e093f0913bf2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9950 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3b5f1c45ba4293b2f8eba7a36a81ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if val_size > 0:\n",
    "    train_val = data[\"train\"].train_test_split(test_size = val_size, shuffle=True, seed=42)\n",
    "    train_data = (train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt))\n",
    "    val_data = (train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt))\n",
    "else:\n",
    "    train_data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "    val_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce0ceb4b-1e0c-4643-8589-be80a18c4f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9950"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6417d157-598f-4c01-9382-7f059ca8b7e7",
   "metadata": {},
   "source": [
    "#### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ca5b43c-ae08-4ede-8771-ce9ce5f32429",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_storage=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ecc43f7-1fce-460a-95d3-5a8d16b7e67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d0b79b80564039b0d50c6d9c37b866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config = quantization_config,\n",
    "    torch_dtype = torch.bfloat16,\n",
    "    device_map = {\"\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9bd7d66-9d99-44b4-b012-2a2877966968",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cd872ae-664b-4ce8-99a3-51fb31c1fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r = 16,\n",
    "    lora_alpha = 16,\n",
    "    target_modules = ['q_proj','k_proj', 'v_proj', 'o_proj'],\n",
    "    lora_dropout = 0.05,\n",
    "    bias = \"none\",\n",
    "    task_type = \"CAUSAL_LM\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de1b7e72-3f3b-4e65-9ba3-e080b7867c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    return list(lora_module_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32d8178e-79d2-44e5-b29a-dcaffa992ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable target module: ['up_proj', 'q_proj', 'gate_proj', 'o_proj', 'v_proj', 'down_proj', 'k_proj']\n"
     ]
    }
   ],
   "source": [
    "print('Trainable target module:', find_all_linear_names(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54704606-a48f-4cdc-981e-89d6b3ecbf63",
   "metadata": {},
   "source": [
    "#### QLoRA Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf927bf7-20d5-4976-82d1-9ecba9830d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "083b44d1-95cb-4ca6-a1bf-141898e642c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "967ff2aa-7c0c-40d9-b0fd-bb45f24fe33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13631488 || all params: 2809401344 || trainable%: 0.4852097059436731\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b59445-8d6f-445e-b9aa-e91b21b93e92",
   "metadata": {},
   "source": [
    "#### Hyper parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5ea0be4-eac2-4554-b4e4-485758e6ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './llama_singleGPU-v1'\n",
    "num_epochs = 1\n",
    "micro_batch_size = 1\n",
    "gradient_accumulation_steps = 8\n",
    "warmup_steps = 10\n",
    "#warmup_steps = 100\n",
    "learning_rate = 5e-8 \n",
    "group_by_length = False\n",
    "optimizer = 'paged_adamw_8bit'\n",
    "\n",
    "# adam 활용시\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "lr_scheduler = 'cosine'\n",
    "#lr_scheduler = 'cosine', 'linear', 'constant'\n",
    "logging_steps = 1\n",
    "\n",
    "use_fp16 = False\n",
    "use_bf_16 = True\n",
    "evaluation_strategy = 'steps'\n",
    "eval_steps = 50\n",
    "save_steps = 50\n",
    "save_strategy = 'steps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed8afac0-b951-460b-8bec-e3431f7015d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6ab73eb-39b1-42d2-ad10-4fa63d78908e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/anaconda3/envs/ksh_llm/lib/python3.9/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    train_dataset = train_data,\n",
    "    eval_dataset = val_data,\n",
    "    args = TrainingArguments(\n",
    "    per_device_train_batch_size = micro_batch_size,\n",
    "    per_device_eval_batch_size = micro_batch_size,\n",
    "    gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "    warmup_steps = warmup_steps,\n",
    "    num_train_epochs = num_epochs,\n",
    "    learning_rate = learning_rate,\n",
    "    adam_beta1 = beta1,\n",
    "    adam_beta2 = beta2,\n",
    "    fp16 = use_fp16,\n",
    "    bf16 = use_bf_16,\n",
    "    logging_steps = logging_steps,\n",
    "    optim = optimizer,\n",
    "    evaluation_strategy = evaluation_strategy if val_size > 0 else \"no\",\n",
    "    save_strategy = 'steps',\n",
    "    eval_steps = eval_steps,\n",
    "    save_steps = save_steps,\n",
    "    lr_scheduler_type = lr_scheduler,\n",
    "    output_dir = output_dir,\n",
    "    #save_total_limit = 4,\n",
    "    load_best_model_at_end = True if val_size > 0 else False,\n",
    "    group_by_length = group_by_length,\n",
    "    report_to = \"wandb\" if use_wandb else None,\n",
    "    run_name = wandb_run_name if use_wandb else None,\n",
    "    ),\n",
    "    data_collator=DataCollatorForSeq2Seq(\n",
    "        tokenizer, pad_to_multiple_of=8, return_tensors='pt', padding=True\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f1bab-98cd-4796-b3bc-4a0e0723e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ec79f-4157-4a24-a471-b0e80ef08031",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9bfa4a-3419-42fe-921e-50f37459d17d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksh_llm",
   "language": "python",
   "name": "ksh_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
